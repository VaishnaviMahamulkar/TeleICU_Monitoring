{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1QhTwy8Ex53SMbdeMSxXMYmeTJPhBFnNp","authorship_tag":"ABX9TyMxQRu1uuNUtaHCQNjC3UnC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"QNV2wwPeoDcg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721062335876,"user_tz":-330,"elapsed":5011,"user":{"displayName":"30,Vaishnavi Mahamulkar","userId":"00542153071655821898"}},"outputId":"af6075f7-659e-49da-f8bc-0a1b62d5a41e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount Google Drive in Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#Import Required Libraries\n","import cv2   #video  capture\n","import os\n"],"metadata":{"id":"iTFn0iGVoHhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define Path\n","video_path = '/content/drive/MyDrive/DataSet_TeleICU.mp4'\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/save_dir'\n","\n","# Create directory if it doesn't exist\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n"],"metadata":{"id":"gGai4Ju_oKiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read Video and Convert to Images Alternately\n","def video_to_images(video_path, save_dir, interval=2):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","    saved_image_count = 0\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        # Save every nth frame\n","        if frame_count % interval == 0:\n","            image_path = os.path.join(save_dir, f'image_{saved_image_count:05d}.jpg')\n","            cv2.imwrite(image_path, frame)\n","            saved_image_count += 1\n","        frame_count += 1\n","\n","    cap.release()\n","    print(f'Total {saved_image_count} images saved.')\n","# Call the function to save every 2th frame as an example\n","video_to_images(video_path, save_dir, interval=2)\n","\n"],"metadata":{"id":"ZUsB_xUioPlX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721049505242,"user_tz":-330,"elapsed":363687,"user":{"displayName":"30,Vaishnavi Mahamulkar","userId":"00542153071655821898"}},"outputId":"7769a55d-2097-4b25-a3da-99c94c8e6085"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total 8384 images saved.\n"]}]},{"cell_type":"code","source":["# Performing k-means Clustering and Saving Segmented Images\n","import cv2\n","import numpy as np\n","import os\n","\n","# Function to perform k-means clustering\n","def perform_kmeans_clustering(image_path, k=3):\n","    # Read image\n","    img = cv2.imread(image_path)\n","    # Convert image to RGB (if it's in BGR format)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    # Reshape image to a 2D array of pixels (height * width, 3)\n","    pixels = img_rgb.reshape((-1, 3))\n","    pixels = np.float32(pixels)\n","\n","    # Define criteria and apply k-means clustering\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n","    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n","\n","    # Convert centers to uint8\n","    centers = np.uint8(centers)\n","\n","    # Reshape labels to match the shape of original image\n","    labels = labels.reshape(img.shape[:2])\n","\n","    # Create segmented image based on k-means clustering\n","    segmented_image = centers[labels]\n","\n","    # Reshape segmented image to match original image shape\n","    segmented_image = segmented_image.reshape(img.shape)\n","\n","    return segmented_image\n","\n","# Path to your directory containing images\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/save_dir'\n","\n","# Directory to save segmented images\n","segmented_dir = '/content/drive/MyDrive/Colab Notebooks/segmented_dir'\n","\n","# Create the segmented directory if it doesn't exist\n","os.makedirs(segmented_dir, exist_ok=True)\n","\n","# List all image files in save_dir\n","image_files = os.listdir(save_dir)\n","\n","# Process each image\n","for img_file in image_files:\n","    img_path = os.path.join(save_dir, img_file)\n","    segmented_img = perform_kmeans_clustering(img_path)\n","\n","    # Save segmented image\n","    segmented_img_path = os.path.join(segmented_dir, f'segmented_{img_file}')\n","    cv2.imwrite(segmented_img_path, segmented_img)\n","\n","print(f'Segmented images saved to {segmented_dir}')"],"metadata":{"id":"Dro90pK9oUiy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model1:-\n","#Splitting the Single Model into 3 Models\n","!pip install ultralytics\n","# Train TOLOv8 Model\n","from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8n.pt')  # Use a lightweight model for faster inference\n","\n","# Train the model\n","model.train(data='coco128.yaml', epochs=50)  # Replace 'coco128.yaml' with your dataset YAML file"],"metadata":{"id":"vZEtoAejoaOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Validate and Test the Model\n","# Validate the model\n","model.val()\n","\n","# Test the model\n","results = model.predict('/path/to/test/images', save=True)\n"],"metadata":{"id":"JaSCy3XUohvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model2:- Detect if Patient is Alone or with Family Members\n","# Assume results from Model 1 are saved\n","model1_results = results  # Replace with actual results\n","\n","# Check if patient is alone or with family members\n","alone = False\n","with_family = False\n","\n","for result in model1_results:\n","    if 'Patient' in result and 'Family Members' in result:\n","        with_family = True\n","    elif 'Patient' in result:\n","        alone = True\n","\n","if alone or with_family:\n","    proceed_to_model3 = True\n","else:\n","    proceed_to_model3 = False\n"],"metadata":{"id":"hO0xVl_9ol5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model3:- Detect Patient Movement\n","#Train YOLOv8 Model for Movement Detection\n","# Define custom dataset YAML file\n","movement_data = '''\n","path: /path/to/dataset\n","train: images/train\n","val: images/val\n","test: images/test\n","\n","nc: 4  # Number of classes\n","names: ['Breathlessness', 'HandLegMovement', 'Fall', 'Wakeup']\n","'''\n","\n","with open('/content/movement_data.yaml', 'w') as f:\n","    f.write(movement_data)\n","\n","# Train the model\n","model_movement = YOLO('yolov8n.pt')\n","model_movement.train(data='/content/movement_data.yaml', epochs=50)"],"metadata":{"id":"xvn4PsiGoi7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Validate and Test the Movement Detection Model\n","# Validate the model\n","model_movement.val()\n","\n","# Test the model\n","movement_results = model_movement.predict('/path/to/test/images', save=True)\n"],"metadata":{"id":"u57iPVS8or8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Alert System\n","#Check Movements and Send Alert\n","alert = False\n","for result in movement_results:\n","    if 'Breathlessness' in result or 'Fall' in result:\n","        alert = True\n","        break\n","\n","if alert:\n","    # Send alert message\n","    print(\"Alert: Immediate attention needed in TeleICU\")\n"],"metadata":{"id":"Rk66_VWnourq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculating Accuracy and Performance Metrics\n","#Calculate Performance Metrics for YOLOv8\n","# Training and Validation\n","from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8n.pt')  # Use a lightweight model for faster inference\n","\n","# Train the model\n","model.train(data='coco128.yaml', epochs=50)  # Replace 'coco128.yaml' with your dataset YAML file\n"],"metadata":{"id":"GS0o5aULoyQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Validation and Metrics Calculation\n","# Validate the model\n","metrics = model.val()\n","\n","# Print the metrics\n","print(metrics)"],"metadata":{"id":"3Q7KKieWo2E9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = model.val()\n","\n","print(\"Precision: \", metrics['precision'])\n","print(\"Recall: \", metrics['recall'])\n","print(\"mAP@0.5: \", metrics['map50'])\n","print(\"mAP@0.5:0.95: \", metrics['map'])"],"metadata":{"id":"LT0sztsco478"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Accuracy\n","# Predict on the Validation Set\n","results = model.predict('/path/to/validation/images', save=True)\n","\n","#Compare Predictions with Ground Truth\n","# Load ground truth annotations\n","with open('/path/to/ground_truth/annotations.json') as f:\n","    ground_truth = json.load(f)\n","\n","# Compare predictions with ground truth\n","correct_predictions = 0\n","total_predictions = len(results)\n","\n","for result, gt in zip(results, ground_truth['annotations']):\n","    # Assuming gt and result have the same format\n","    if result['category_id'] == gt['category_id']:\n","        correct_predictions += 1\n","\n","accuracy = correct_predictions / total_predictions\n","print(\"Accuracy: \", accuracy)\n"],"metadata":{"id":"2RvlZpsDo7p5"},"execution_count":null,"outputs":[]}]}